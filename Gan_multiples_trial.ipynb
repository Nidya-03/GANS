{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "i2_6IkMqh0Ra"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Install needed packages\n",
        "!pip install pandas numpy tensorflow faker\n",
        "\n",
        "# Step 2: Import\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# Step 3: Load your CSV file\n",
        "df = pd.read_csv('/content/Customer.csv')  # Replace with your uploaded file\n",
        "\n",
        "# Step 4: Convert DOB to age\n",
        "df['date_of_birth'] = pd.to_datetime(df['date_of_birth'], errors='coerce')\n",
        "today = pd.to_datetime('today')\n",
        "df['age'] = (today.year - df['date_of_birth'].dt.year).fillna(30).astype(int)\n",
        "\n",
        "# Step 5: Normalize the age values between -1 and 1\n",
        "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
        "age_scaled = scaler.fit_transform(df[['age']])\n",
        "\n",
        "# Step 6: Define the Generator\n",
        "def build_generator():\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.Input(shape=(10,)),\n",
        "        layers.Dense(16, activation='relu'),\n",
        "        layers.Dense(32, activation='relu'),\n",
        "        layers.Dense(1, activation='tanh')  # Output a single value\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# Step 7: Define the Discriminator\n",
        "def build_discriminator():\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.Input(shape=(1,)),\n",
        "        layers.Dense(32, activation='relu'),\n",
        "        layers.Dense(16, activation='relu'),\n",
        "        layers.Dense(1, activation='sigmoid')  # 1 for real, 0 for fake\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# Step 8: Instantiate the models\n",
        "generator = build_generator()\n",
        "discriminator = build_discriminator()\n",
        "\n",
        "# Step 9: Compile the Discriminator\n",
        "discriminator.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Step 10: Build and Compile the GAN\n",
        "discriminator.trainable = False\n",
        "gan_input = tf.keras.Input(shape=(10,))\n",
        "gan_output = discriminator(generator(gan_input))\n",
        "gan = tf.keras.Model(gan_input, gan_output)\n",
        "gan.compile(optimizer='adam', loss='binary_crossentropy')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xrIyD4SypIZT",
        "outputId": "c6991ca7-0bed-4b9a-fd66-539a1fd40d21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Collecting faker\n",
            "  Downloading faker-37.3.0-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.14.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.72.1)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.4.26)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.8)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
            "Downloading faker-37.3.0-py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faker\n",
            "Successfully installed faker-37.3.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-1-5be63f9004a3>:15: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
            "  df['date_of_birth'] = pd.to_datetime(df['date_of_birth'], errors='coerce')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Rebuild Generator\n",
        "def build_generator():\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.Input(shape=(10,)),\n",
        "        layers.Dense(16, activation='relu'),\n",
        "        layers.Dense(32, activation='relu'),\n",
        "        layers.Dense(1, activation='tanh')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# Rebuild Discriminator\n",
        "def build_discriminator():\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.Input(shape=(1,)),\n",
        "        layers.Dense(32, activation='relu'),\n",
        "        layers.Dense(16, activation='relu'),\n",
        "        layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# Re-create the models\n",
        "generator = build_generator()\n",
        "discriminator = build_discriminator()\n",
        "\n",
        "# Compile the discriminator first\n",
        "discriminator.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Freeze discriminator\n",
        "discriminator.trainable = False\n",
        "\n",
        "# Build GAN model\n",
        "gan_input = tf.keras.Input(shape=(10,))\n",
        "gan_output = discriminator(generator(gan_input))\n",
        "gan = tf.keras.Model(gan_input, gan_output)\n",
        "\n",
        "# Compile GAN\n",
        "gan.compile(optimizer='adam', loss='binary_crossentropy')"
      ],
      "metadata": {
        "id": "TIIL9DItpT9w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Assume generator is your trained Keras model from before\n",
        "num_samples = 1000\n",
        "noise_dim = 10  # match your generator input\n",
        "\n",
        "noise = np.random.normal(0, 1, (num_samples, noise_dim))\n",
        "generated_scaled_ages = generator.predict(noise)\n",
        "\n",
        "synthetic_ages = scaler.inverse_transform(generated_scaled_ages)\n",
        "synthetic_ages = synthetic_ages.flatten().astype(int)\n",
        "\n",
        "print(synthetic_ages[:10])\n",
        "\n",
        "# Inverse transform to original age scale\n",
        "# Assuming you used MinMaxScaler fitted on real ages earlier as 'scaler'\n",
        "synthetic_ages = scaler.inverse_transform(generated_scaled_ages)\n",
        "\n",
        "# Convert to integer ages\n",
        "synthetic_ages = synthetic_ages.flatten().astype(int)\n",
        "\n",
        "print(synthetic_ages[:10])  # Check first 10 synthetic ages"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3d1zYYVwp5QL",
        "outputId": "edc26cec-8e6f-4280-9b20-ab1497771951"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "[30 30 30 30 30 30 30 30 30 30]\n",
            "[30 30 30 30 30 30 30 30 30 30]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 11: Train the GAN\n",
        "epochs = 5000\n",
        "batch_size = 32\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    # Real samples\n",
        "    idx = np.random.randint(0, age_scaled.shape[0], batch_size)\n",
        "    real_ages = age_scaled[idx]\n",
        "\n",
        "    # Fake samples\n",
        "    noise = np.random.normal(0, 1, (batch_size, 10))\n",
        "    fake_ages = generator.predict(noise, verbose=0)\n",
        "\n",
        "    # Train discriminator\n",
        "    d_loss_real = discriminator.train_on_batch(real_ages, np.ones((batch_size, 1)))\n",
        "    d_loss_fake = discriminator.train_on_batch(fake_ages, np.zeros((batch_size, 1)))\n",
        "\n",
        "    # Train generator\n",
        "    noise = np.random.normal(0, 1, (batch_size, 10))\n",
        "    g_loss = gan.train_on_batch(noise, np.ones((batch_size, 1)))\n",
        "\n",
        "    # Print progress\n",
        "    if epoch % 100 == 0:\n",
        "        print(f\"{epoch} [D loss: {(d_loss_real[0] + d_loss_fake[0]):.4f}] [G loss: {g_loss:.4f}]\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dnnYhp93pdrb",
        "outputId": "4271d930-b5ec-464b-96b5-a14da7206184"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 [D loss: 1.3089] [G loss: 0.6188]\n",
            "100 [D loss: 1.3398] [G loss: 0.5936]\n",
            "200 [D loss: 1.3480] [G loss: 0.5870]\n",
            "300 [D loss: 1.3518] [G loss: 0.5841]\n",
            "400 [D loss: 1.3539] [G loss: 0.5824]\n",
            "500 [D loss: 1.3552] [G loss: 0.5813]\n",
            "600 [D loss: 1.3562] [G loss: 0.5805]\n",
            "700 [D loss: 1.3569] [G loss: 0.5800]\n",
            "800 [D loss: 1.3574] [G loss: 0.5795]\n",
            "900 [D loss: 1.3579] [G loss: 0.5792]\n",
            "1000 [D loss: 1.3582] [G loss: 0.5789]\n",
            "1100 [D loss: 1.3585] [G loss: 0.5787]\n",
            "1200 [D loss: 1.3587] [G loss: 0.5785]\n",
            "1300 [D loss: 1.3589] [G loss: 0.5783]\n",
            "1400 [D loss: 1.3591] [G loss: 0.5782]\n",
            "1500 [D loss: 1.3593] [G loss: 0.5781]\n",
            "1600 [D loss: 1.3594] [G loss: 0.5780]\n",
            "1700 [D loss: 1.3595] [G loss: 0.5779]\n",
            "1800 [D loss: 1.3596] [G loss: 0.5778]\n",
            "1900 [D loss: 1.3597] [G loss: 0.5777]\n",
            "2000 [D loss: 1.3598] [G loss: 0.5776]\n",
            "2100 [D loss: 1.3599] [G loss: 0.5776]\n",
            "2200 [D loss: 1.3600] [G loss: 0.5775]\n",
            "2300 [D loss: 1.3600] [G loss: 0.5775]\n",
            "2400 [D loss: 1.3601] [G loss: 0.5774]\n",
            "2500 [D loss: 1.3602] [G loss: 0.5774]\n",
            "2600 [D loss: 1.3602] [G loss: 0.5773]\n",
            "2700 [D loss: 1.3603] [G loss: 0.5773]\n",
            "2800 [D loss: 1.3603] [G loss: 0.5773]\n",
            "2900 [D loss: 1.3604] [G loss: 0.5772]\n",
            "3000 [D loss: 1.3604] [G loss: 0.5772]\n",
            "3100 [D loss: 1.3604] [G loss: 0.5772]\n",
            "3200 [D loss: 1.3605] [G loss: 0.5771]\n",
            "3300 [D loss: 1.3605] [G loss: 0.5771]\n",
            "3400 [D loss: 1.3606] [G loss: 0.5771]\n",
            "3500 [D loss: 1.3606] [G loss: 0.5771]\n",
            "3600 [D loss: 1.3606] [G loss: 0.5771]\n",
            "3700 [D loss: 1.3607] [G loss: 0.5770]\n",
            "3800 [D loss: 1.3607] [G loss: 0.5770]\n",
            "3900 [D loss: 1.3607] [G loss: 0.5770]\n",
            "4000 [D loss: 1.3607] [G loss: 0.5770]\n",
            "4100 [D loss: 1.3608] [G loss: 0.5770]\n",
            "4200 [D loss: 1.3608] [G loss: 0.5770]\n",
            "4300 [D loss: 1.3608] [G loss: 0.5769]\n",
            "4400 [D loss: 1.3608] [G loss: 0.5769]\n",
            "4500 [D loss: 1.3609] [G loss: 0.5769]\n",
            "4600 [D loss: 1.3609] [G loss: 0.5769]\n",
            "4700 [D loss: 1.3609] [G loss: 0.5769]\n",
            "4800 [D loss: 1.3609] [G loss: 0.5769]\n",
            "4900 [D loss: 1.3609] [G loss: 0.5769]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install ctgan"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ndt9O_sfsKy0",
        "outputId": "cca4bca5-0577-48f9-cc8b-6d853964b6d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ctgan in /usr/local/lib/python3.11/dist-packages (0.11.0)\n",
            "Requirement already satisfied: numpy>=1.23.3 in /usr/local/lib/python3.11/dist-packages (from ctgan) (2.0.2)\n",
            "Requirement already satisfied: pandas>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from ctgan) (2.2.2)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ctgan) (2.6.0+cu124)\n",
            "Requirement already satisfied: tqdm<5,>=4.29 in /usr/local/lib/python3.11/dist-packages (from ctgan) (4.67.1)\n",
            "Requirement already satisfied: rdt>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from ctgan) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.5.0->ctgan) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.5.0->ctgan) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.5.0->ctgan) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.9.2 in /usr/local/lib/python3.11/dist-packages (from rdt>=1.14.0->ctgan) (1.15.3)\n",
            "Requirement already satisfied: scikit-learn>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from rdt>=1.14.0->ctgan) (1.6.1)\n",
            "Requirement already satisfied: Faker>=17 in /usr/local/lib/python3.11/dist-packages (from rdt>=1.14.0->ctgan) (37.3.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->ctgan) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->ctgan) (4.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->ctgan) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->ctgan) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->ctgan) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->ctgan) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->ctgan) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->ctgan) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->ctgan) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->ctgan) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->ctgan) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->ctgan) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->ctgan) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->ctgan) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->ctgan) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->ctgan) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->ctgan) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->ctgan) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->ctgan) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->ctgan) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->ctgan) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.5.0->ctgan) (1.17.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.1.3->rdt>=1.14.0->ctgan) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.1.3->rdt>=1.14.0->ctgan) (3.6.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->ctgan) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from ctgan import CTGAN\n",
        "# Load your real dataset\n",
        "real_data = pd.read_csv(\"Customer.csv\")\n",
        "\n",
        "# Drop unique ID for training\n",
        "real_data = real_data.drop(columns=[\"customer_id\"])\n",
        "\n",
        "# Define categorical columns\n",
        "categorical_columns = [\"first_name\", \"last_name\", \"date_of_birth\", \"address\", \"phone_number\"]\n",
        "\n",
        "# Initialize CTGAN model\n",
        "ctgan = CTGAN(epochs=300)  # train for 300 epochs\n",
        "\n",
        "# Train the model\n",
        "ctgan.fit(real_data, discrete_columns=categorical_columns)\n",
        "\n",
        "# Generate synthetic data samples\n",
        "synthetic_data = ctgan.sample(500)\n",
        "\n",
        "# Add synthetic UUIDs for customer_id\n",
        "import uuid\n",
        "synthetic_data[\"customer_id\"] = [str(uuid.uuid4()) for _ in range(len(synthetic_data))]\n",
        "\n",
        "# Reorder columns\n",
        "cols = [\"customer_id\"] + [col for col in synthetic_data.columns if col != \"customer_id\"]\n",
        "synthetic_data = synthetic_data[cols]\n",
        "\n",
        "print(synthetic_data.head())\n",
        "\n",
        "synthetic_data.to_csv(\"synthetic_CTGan_customers.csv\", index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gevBJL-tsJCN",
        "outputId": "53207932-38f0-4bf7-acf1-b714bb5583a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                            customer_id first_name last_name date_of_birth  \\\n",
            "0  12736124-0ff1-4c46-8ffc-b8b797afef20     Smythe   Casarez    10/17/1971   \n",
            "1  42df858e-a5b1-40d7-9c76-67d63ff49661    Killian     Shine     6/17/1971   \n",
            "2  dcc5122b-22c5-4fea-9972-4acc7d459de8    Salazar  Trinidad    11/10/1971   \n",
            "3  9b38282f-dfda-4c8d-bbab-882de055e8e6    Varnado    Urbano      6/1/1971   \n",
            "4  4a7dd2a9-3a61-4107-8f91-fcbc4840e873  Cardinale      Maya    10/17/1971   \n",
            "\n",
            "      address    phone_number  \n",
            "0    Sec-1998  (557) 557-7957  \n",
            "1    Sec-1158  (713) 413-4513  \n",
            "2      B-1681  (750) 450-5150  \n",
            "3      D-1244  (620) 620-9220  \n",
            "4  Block-1418  (656) 256-7456  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "multiple files\n"
      ],
      "metadata": {
        "id": "TETrWM3tfLtm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Uninstall SDV completely first (clears broken or old install)\n",
        "!pip uninstall -y sdv\n",
        "!pip install -U pip setuptools wheel\n",
        "\n",
        "# Reinstall the correct latest SDV version (v1.0.0+)\n",
        "!pip install sdv==1.0.1\n",
        "\n"
      ],
      "metadata": {
        "id": "Ppez_C9KhVcU",
        "outputId": "91d38ae9-379b-463e-d590-7d2e4de88d3e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 674
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: sdv 1.22.1\n",
            "Uninstalling sdv-1.22.1:\n",
            "  Successfully uninstalled sdv-1.22.1\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.11/dist-packages (24.1.2)\n",
            "Collecting pip\n",
            "  Downloading pip-25.1.1-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (75.2.0)\n",
            "Collecting setuptools\n",
            "  Downloading setuptools-80.9.0-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.11/dist-packages (0.45.1)\n",
            "Downloading pip-25.1.1-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m58.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading setuptools-80.9.0-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m65.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: setuptools, pip\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 75.2.0\n",
            "    Uninstalling setuptools-75.2.0:\n",
            "      Successfully uninstalled setuptools-75.2.0\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 24.1.2\n",
            "    Uninstalling pip-24.1.2:\n",
            "      Successfully uninstalled pip-24.1.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed pip-25.1.1 setuptools-80.9.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "_distutils_hack",
                  "pkg_resources"
                ]
              },
              "id": "6754dd86c5c34e75bcb2e74cbf60e6fe"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Ignored the following yanked versions: 1.13.0\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Ignored the following versions that require a different python version: 0.10.0 Requires-Python >=3.6,<3.9; 0.10.0.dev0 Requires-Python >=3.6,<3.9; 0.10.1 Requires-Python >=3.6,<3.9; 0.10.1.dev0 Requires-Python >=3.6,<3.9; 0.11.0 Requires-Python >=3.6,<3.9; 0.11.0.dev0 Requires-Python >=3.6,<3.9; 0.12.0 Requires-Python >=3.6,<3.9; 0.12.0.dev0 Requires-Python >=3.6,<3.9; 0.12.0.dev1 Requires-Python >=3.6,<3.9; 0.12.1 Requires-Python >=3.6,<3.9; 0.12.1.dev0 Requires-Python >=3.6,<3.9; 0.13.0 Requires-Python >=3.6,<3.10; 0.13.0.dev0 Requires-Python >=3.6,<3.10; 0.13.1 Requires-Python >=3.6,<3.10; 0.13.1.dev0 Requires-Python >=3.6,<3.10; 0.14.0 Requires-Python >=3.6,<3.10; 0.14.0.dev0 Requires-Python >=3.6,<3.10; 0.14.0.dev1 Requires-Python >=3.6,<3.10; 0.14.0.dev2 Requires-Python >=3.6,<3.10; 0.14.1 Requires-Python >=3.6,<3.10; 0.14.1.dev0 Requires-Python >=3.6,<3.10; 0.15.0 Requires-Python >=3.6,<3.10; 0.15.0.dev0 Requires-Python >=3.6,<3.10; 0.15.0.dev1 Requires-Python >=3.6,<3.10; 0.16.0 Requires-Python >=3.6,<3.10; 0.16.0.dev0 Requires-Python >=3.6,<3.10; 0.16.0.dev1 Requires-Python >=3.6,<3.10; 0.16.0.dev2 Requires-Python >=3.6,<3.10; 0.16.0.dev3 Requires-Python >=3.6,<3.10; 0.16.0.dev4 Requires-Python >=3.6,<3.10; 0.16.0.dev5 Requires-Python >=3.6,<3.10; 0.17.0 Requires-Python >=3.6,<3.10; 0.17.0.dev0 Requires-Python >=3.6,<3.10; 0.17.0.dev1 Requires-Python >=3.6,<3.10; 0.17.0.dev2 Requires-Python >=3.6,<3.10; 0.17.1 Requires-Python >=3.6,<3.10; 0.17.1.dev0 Requires-Python >=3.6,<3.10; 0.17.2 Requires-Python >=3.6,<3.10; 0.17.2.dev0 Requires-Python >=3.6,<3.10; 0.18.0 Requires-Python >=3.7,<3.11; 0.18.0.dev0 Requires-Python >=3.7,<3.11; 0.3.3 Requires-Python >=3.5,<3.8; 0.3.4 Requires-Python >=3.5,<3.8; 0.3.4.dev0 Requires-Python >=3.5,<3.8; 0.3.5 Requires-Python >=3.5,<3.8; 0.3.6 Requires-Python >=3.5,<3.8; 0.3.6.dev0 Requires-Python >=3.5,<3.8; 0.4.0 Requires-Python >=3.5,<3.9; 0.4.0.dev0 Requires-Python >=3.5,<3.9; 0.4.1 Requires-Python >=3.5,<3.9; 0.4.1.dev0 Requires-Python >=3.5,<3.9; 0.4.2 Requires-Python >=3.5,<3.9; 0.4.3 Requires-Python >=3.5,<3.9; 0.4.4 Requires-Python >=3.5,<3.9; 0.4.4.dev0 Requires-Python >=3.5,<3.9; 0.4.5 Requires-Python >=3.6,<3.9; 0.4.6.dev0 Requires-Python >=3.6,<3.9; 0.4.6.dev1 Requires-Python >=3.6,<3.9; 0.4.6.dev2 Requires-Python >=3.6,<3.9; 0.5.0 Requires-Python >=3.6,<3.9; 0.5.0.dev0 Requires-Python >=3.6,<3.9; 0.6.0 Requires-Python >=3.6,<3.9; 0.6.0.dev0 Requires-Python >=3.6,<3.9; 0.6.1 Requires-Python >=3.6,<3.9; 0.6.2.dev0 Requires-Python >=3.6,<3.9; 0.6.2.dev1 Requires-Python >=3.6,<3.9; 0.6.2.dev2 Requires-Python >=3.6,<3.9; 0.7.0 Requires-Python >=3.6,<3.9; 0.7.0.dev0 Requires-Python >=3.6,<3.9; 0.7.0.dev1 Requires-Python >=3.6,<3.9; 0.8.0 Requires-Python >=3.6,<3.9; 0.8.0.dev0 Requires-Python >=3.6,<3.9; 0.9.0 Requires-Python >=3.6,<3.9; 0.9.0.dev0 Requires-Python >=3.6,<3.9; 0.9.1 Requires-Python >=3.6,<3.9; 0.9.1.dev0 Requires-Python >=3.6,<3.9; 0.9.1.dev1 Requires-Python >=3.6,<3.9; 1.0.0 Requires-Python >=3.7,<3.11; 1.0.0b0 Requires-Python >=3.7,<3.11; 1.0.0b1 Requires-Python >=3.7,<3.11; 1.0.0rc0 Requires-Python >=3.7,<3.11; 1.0.1 Requires-Python >=3.7,<3.11; 1.0.1.dev0 Requires-Python >=3.7,<3.11; 1.1.0 Requires-Python >=3.7,<3.11; 1.1.0.dev0 Requires-Python >=3.7,<3.11; 1.2.0 Requires-Python >=3.7,<3.11; 1.2.0.dev0 Requires-Python >=3.7,<3.11; 1.2.0.dev1 Requires-Python >=3.7,<3.11; 1.2.1 Requires-Python >=3.8,<3.11; 1.2.1.dev0 Requires-Python >=3.8,<3.11; 1.2.2.dev0 Requires-Python >=3.8,<3.11; 1.2.2.dev1 Requires-Python >=3.8,<3.11\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement sdv==1.0.1 (from versions: 0.0.0, 0.1.0, 0.1.1, 0.1.2, 0.2.0.dev0, 0.2.0, 0.2.1, 0.2.2, 0.3.0, 0.3.1, 0.3.2, 1.3.0.dev0, 1.3.0.dev1, 1.3.0, 1.4.0.dev0, 1.4.0.dev1, 1.4.0, 1.5.0.dev0, 1.5.0, 1.6.0.dev0, 1.6.0.dev1, 1.6.0, 1.7.0.dev0, 1.7.0, 1.8.0.dev0, 1.8.0, 1.9.0.dev0, 1.9.0, 1.10.0.dev0, 1.10.0, 1.11.0.dev0, 1.11.0, 1.12.0.dev0, 1.12.0, 1.12.1.dev0, 1.12.1.dev1, 1.12.1, 1.13.0.dev0, 1.13.1.dev0, 1.13.1, 1.14.0.dev0, 1.14.0, 1.15.0.dev0, 1.15.0, 1.16.0.dev0, 1.16.0, 1.16.1.dev0, 1.16.1, 1.16.2.dev0, 1.16.2, 1.17.0.dev0, 1.17.0.dev1, 1.17.0, 1.17.1.dev0, 1.17.1, 1.17.2.dev0, 1.17.2.dev1, 1.17.2, 1.17.3.dev0, 1.17.3, 1.17.4.dev0, 1.17.4, 1.18.0.dev0, 1.18.0, 1.19.0.dev0, 1.19.0, 1.20.0.dev0, 1.20.0, 1.20.1.dev0, 1.20.1, 1.21.0.dev0, 1.21.0, 1.22.0.dev0, 1.22.0, 1.22.1.dev0, 1.22.1)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for sdv==1.0.1\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install compatible SDV version\n",
        "!pip uninstall -y sdv\n",
        "!pip install sdv==1.0.1\n"
      ],
      "metadata": {
        "id": "TMn1mx5uiY3B",
        "outputId": "49378501-3f28-46e0-9c6f-644e6efa673b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: sdv 1.22.1\n",
            "Uninstalling sdv-1.22.1:\n",
            "  Successfully uninstalled sdv-1.22.1\n",
            "\u001b[31mERROR: Ignored the following yanked versions: 1.13.0\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Ignored the following versions that require a different python version: 0.10.0 Requires-Python >=3.6,<3.9; 0.10.0.dev0 Requires-Python >=3.6,<3.9; 0.10.1 Requires-Python >=3.6,<3.9; 0.10.1.dev0 Requires-Python >=3.6,<3.9; 0.11.0 Requires-Python >=3.6,<3.9; 0.11.0.dev0 Requires-Python >=3.6,<3.9; 0.12.0 Requires-Python >=3.6,<3.9; 0.12.0.dev0 Requires-Python >=3.6,<3.9; 0.12.0.dev1 Requires-Python >=3.6,<3.9; 0.12.1 Requires-Python >=3.6,<3.9; 0.12.1.dev0 Requires-Python >=3.6,<3.9; 0.13.0 Requires-Python >=3.6,<3.10; 0.13.0.dev0 Requires-Python >=3.6,<3.10; 0.13.1 Requires-Python >=3.6,<3.10; 0.13.1.dev0 Requires-Python >=3.6,<3.10; 0.14.0 Requires-Python >=3.6,<3.10; 0.14.0.dev0 Requires-Python >=3.6,<3.10; 0.14.0.dev1 Requires-Python >=3.6,<3.10; 0.14.0.dev2 Requires-Python >=3.6,<3.10; 0.14.1 Requires-Python >=3.6,<3.10; 0.14.1.dev0 Requires-Python >=3.6,<3.10; 0.15.0 Requires-Python >=3.6,<3.10; 0.15.0.dev0 Requires-Python >=3.6,<3.10; 0.15.0.dev1 Requires-Python >=3.6,<3.10; 0.16.0 Requires-Python >=3.6,<3.10; 0.16.0.dev0 Requires-Python >=3.6,<3.10; 0.16.0.dev1 Requires-Python >=3.6,<3.10; 0.16.0.dev2 Requires-Python >=3.6,<3.10; 0.16.0.dev3 Requires-Python >=3.6,<3.10; 0.16.0.dev4 Requires-Python >=3.6,<3.10; 0.16.0.dev5 Requires-Python >=3.6,<3.10; 0.17.0 Requires-Python >=3.6,<3.10; 0.17.0.dev0 Requires-Python >=3.6,<3.10; 0.17.0.dev1 Requires-Python >=3.6,<3.10; 0.17.0.dev2 Requires-Python >=3.6,<3.10; 0.17.1 Requires-Python >=3.6,<3.10; 0.17.1.dev0 Requires-Python >=3.6,<3.10; 0.17.2 Requires-Python >=3.6,<3.10; 0.17.2.dev0 Requires-Python >=3.6,<3.10; 0.18.0 Requires-Python >=3.7,<3.11; 0.18.0.dev0 Requires-Python >=3.7,<3.11; 0.3.3 Requires-Python >=3.5,<3.8; 0.3.4 Requires-Python >=3.5,<3.8; 0.3.4.dev0 Requires-Python >=3.5,<3.8; 0.3.5 Requires-Python >=3.5,<3.8; 0.3.6 Requires-Python >=3.5,<3.8; 0.3.6.dev0 Requires-Python >=3.5,<3.8; 0.4.0 Requires-Python >=3.5,<3.9; 0.4.0.dev0 Requires-Python >=3.5,<3.9; 0.4.1 Requires-Python >=3.5,<3.9; 0.4.1.dev0 Requires-Python >=3.5,<3.9; 0.4.2 Requires-Python >=3.5,<3.9; 0.4.3 Requires-Python >=3.5,<3.9; 0.4.4 Requires-Python >=3.5,<3.9; 0.4.4.dev0 Requires-Python >=3.5,<3.9; 0.4.5 Requires-Python >=3.6,<3.9; 0.4.6.dev0 Requires-Python >=3.6,<3.9; 0.4.6.dev1 Requires-Python >=3.6,<3.9; 0.4.6.dev2 Requires-Python >=3.6,<3.9; 0.5.0 Requires-Python >=3.6,<3.9; 0.5.0.dev0 Requires-Python >=3.6,<3.9; 0.6.0 Requires-Python >=3.6,<3.9; 0.6.0.dev0 Requires-Python >=3.6,<3.9; 0.6.1 Requires-Python >=3.6,<3.9; 0.6.2.dev0 Requires-Python >=3.6,<3.9; 0.6.2.dev1 Requires-Python >=3.6,<3.9; 0.6.2.dev2 Requires-Python >=3.6,<3.9; 0.7.0 Requires-Python >=3.6,<3.9; 0.7.0.dev0 Requires-Python >=3.6,<3.9; 0.7.0.dev1 Requires-Python >=3.6,<3.9; 0.8.0 Requires-Python >=3.6,<3.9; 0.8.0.dev0 Requires-Python >=3.6,<3.9; 0.9.0 Requires-Python >=3.6,<3.9; 0.9.0.dev0 Requires-Python >=3.6,<3.9; 0.9.1 Requires-Python >=3.6,<3.9; 0.9.1.dev0 Requires-Python >=3.6,<3.9; 0.9.1.dev1 Requires-Python >=3.6,<3.9; 1.0.0 Requires-Python >=3.7,<3.11; 1.0.0b0 Requires-Python >=3.7,<3.11; 1.0.0b1 Requires-Python >=3.7,<3.11; 1.0.0rc0 Requires-Python >=3.7,<3.11; 1.0.1 Requires-Python >=3.7,<3.11; 1.0.1.dev0 Requires-Python >=3.7,<3.11; 1.1.0 Requires-Python >=3.7,<3.11; 1.1.0.dev0 Requires-Python >=3.7,<3.11; 1.2.0 Requires-Python >=3.7,<3.11; 1.2.0.dev0 Requires-Python >=3.7,<3.11; 1.2.0.dev1 Requires-Python >=3.7,<3.11; 1.2.1 Requires-Python >=3.8,<3.11; 1.2.1.dev0 Requires-Python >=3.8,<3.11; 1.2.2.dev0 Requires-Python >=3.8,<3.11; 1.2.2.dev1 Requires-Python >=3.8,<3.11\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement sdv==1.0.1 (from versions: 0.0.0, 0.1.0, 0.1.1, 0.1.2, 0.2.0.dev0, 0.2.0, 0.2.1, 0.2.2, 0.3.0, 0.3.1, 0.3.2, 1.3.0.dev0, 1.3.0.dev1, 1.3.0, 1.4.0.dev0, 1.4.0.dev1, 1.4.0, 1.5.0.dev0, 1.5.0, 1.6.0.dev0, 1.6.0.dev1, 1.6.0, 1.7.0.dev0, 1.7.0, 1.8.0.dev0, 1.8.0, 1.9.0.dev0, 1.9.0, 1.10.0.dev0, 1.10.0, 1.11.0.dev0, 1.11.0, 1.12.0.dev0, 1.12.0, 1.12.1.dev0, 1.12.1.dev1, 1.12.1, 1.13.0.dev0, 1.13.1.dev0, 1.13.1, 1.14.0.dev0, 1.14.0, 1.15.0.dev0, 1.15.0, 1.16.0.dev0, 1.16.0, 1.16.1.dev0, 1.16.1, 1.16.2.dev0, 1.16.2, 1.17.0.dev0, 1.17.0.dev1, 1.17.0, 1.17.1.dev0, 1.17.1, 1.17.2.dev0, 1.17.2.dev1, 1.17.2, 1.17.3.dev0, 1.17.3, 1.17.4.dev0, 1.17.4, 1.18.0.dev0, 1.18.0, 1.19.0.dev0, 1.19.0, 1.20.0.dev0, 1.20.0, 1.20.1.dev0, 1.20.1, 1.21.0.dev0, 1.21.0, 1.22.0.dev0, 1.22.0, 1.22.1.dev0, 1.22.1)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for sdv==1.0.1\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 1: Import Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "\n",
        "# NEW: Import CTGAN-compatible modules from SDV\n",
        "from sdv.single_table import CTGANSynthesizer\n",
        "from sdv.metadata import SingleTableMetadata\n",
        "\n"
      ],
      "metadata": {
        "id": "T9RpzPXFOlpd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "# STEP 2: Upload CSV files (Upload all 10: 4 lookup + 6 main)\n",
        "print(\"Please upload your 10 CSV files: 4 lookup tables + 6 main tables\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "# STEP 3: Read all uploaded tables\n",
        "dataframes = {}\n",
        "for file_name in uploaded.keys():\n",
        "    df_name = os.path.splitext(file_name)[0]\n",
        "    dataframes[df_name] = pd.read_csv(file_name)\n",
        "print(f\"\\n✅ Uploaded Tables: {list(dataframes.keys())}\")\n",
        "\n",
        "# STEP 4: Define which are lookup and which are main tables\n",
        "lookup_tables = ['PolicyStatus', 'PolicyType', 'CoverageType', 'PaymentMethod']\n",
        "main_tables = ['Customer', 'Policy', 'Coverage', 'Premium', 'Claim', 'Beneficiary']\n",
        "\n",
        "# # STEP 5: Synthetic Data Generator using CTGAN\n",
        "# def generate_ctgan(data, table_name, epochs=300):\n",
        "#     metadata = SingleTableMetadata()\n",
        "#     metadata.detect_from_dataframe(data=data)\n",
        "\n",
        "#     model = CTGANSynthesizer(epochs=epochs)\n",
        "#     model.fit(data)\n",
        "#     synthetic = model.sample(num_rows=len(data))\n",
        "\n",
        "#     score = evaluate_quality(data, synthetic, metadata)\n",
        "#     print(f\"Generated: {table_name} | Quality Score: {score['Quality Score']:.2f}\")\n",
        "#     return synthetic\n",
        "\n",
        "\n",
        "def generate_ctgan(data, table_name, epochs=300):\n",
        "    metadata = SingleTableMetadata()\n",
        "    metadata.detect_from_dataframe(data=data)\n",
        "\n",
        "    # Pass metadata explicitly when creating the model\n",
        "    model = CTGANSynthesizer(metadata=metadata, epochs=epochs)\n",
        "    model.fit(data)\n",
        "    synthetic = model.sample(num_rows=len(data))\n",
        "    print(f\"✅ Generated synthetic data for {table_name}\")\n",
        "    return synthetic\n",
        "\n"
      ],
      "metadata": {
        "id": "QyMFEn-0hds9",
        "outputId": "5297ceb7-5c84-4f63-a456-589664dcb2f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please upload your 10 CSV files: 4 lookup tables + 6 main tables\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-78dd667f-107e-42f8-b9b5-62d10c2c030d\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-78dd667f-107e-42f8-b9b5-62d10c2c030d\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Beneficiary.csv to Beneficiary.csv\n",
            "Saving Claim.csv to Claim.csv\n",
            "Saving Coverage.csv to Coverage.csv\n",
            "Saving CoverageType.csv to CoverageType.csv\n",
            "Saving Customer.csv to Customer.csv\n",
            "Saving PaymentMethod.csv to PaymentMethod.csv\n",
            "Saving Policy.csv to Policy.csv\n",
            "Saving PolicyStatus.csv to PolicyStatus.csv\n",
            "Saving PolicyType.csv to PolicyType.csv\n",
            "Saving Premium.csv to Premium.csv\n",
            "\n",
            "✅ Uploaded Tables: ['Beneficiary', 'Claim', 'Coverage', 'CoverageType', 'Customer', 'PaymentMethod', 'Policy', 'PolicyStatus', 'PolicyType', 'Premium']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(list(dataframes.keys()))\n"
      ],
      "metadata": {
        "id": "FRJ0GPyGknrh",
        "outputId": "12b2438f-e197-4ebc-8e96-6f5f68feaeb0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Beneficiary', 'Claim', 'Coverage', 'CoverageType', 'Customer', 'PaymentMethod', 'Policy', 'PolicyStatus', 'PolicyType', 'Premium']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 6: Generate synthetic Customer table (independent)\n",
        "synthetic_data = {}\n",
        "synthetic_data['Customer'] = generate_ctgan(dataframes['Customer'], 'Customer')\n",
        "\n",
        "# STEP 7: Generate synthetic Policy table\n",
        "policy_input = dataframes['Policy'].copy()\n",
        "policy_input['customer_id'] = np.random.choice(synthetic_data['Customer']['customer_id'], size=len(policy_input))\n",
        "policy_input['status_id'] = np.random.choice(dataframes['PolicyStatus']['status_id'], size=len(policy_input))\n",
        "policy_input['type_id'] = np.random.choice(dataframes['PolicyType']['type_id'], size=len(policy_input))\n",
        "synthetic_data['Policy'] = generate_ctgan(policy_input, 'Policy')\n",
        "\n",
        "# STEP 8: Generate Coverage table\n",
        "coverage_input = dataframes['Coverage'].copy()\n",
        "coverage_input['policy_id'] = np.random.choice(synthetic_data['Policy']['policy_id'], size=len(coverage_input))\n",
        "coverage_input['coverage_id'] = np.random.choice(dataframes['CoverageType']['coverage_id'], size=len(coverage_input))\n",
        "synthetic_data['Coverage'] = generate_ctgan(coverage_input, 'Coverage')\n",
        "\n",
        "# STEP 9: Generate Premium table\n",
        "premium_input = dataframes['Premium'].copy()\n",
        "premium_input['policy_id'] = np.random.choice(synthetic_data['Policy']['policy_id'], size=len(premium_input))\n",
        "premium_input['method_id'] = np.random.choice(dataframes['PaymentMethod']['method_id'], size=len(premium_input))\n",
        "synthetic_data['Premium'] = generate_ctgan(premium_input, 'Premium')"
      ],
      "metadata": {
        "id": "QLJWvjMgfV3i",
        "outputId": "c989755e-7103-41a9-9794-02f728373bf4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sdv/single_table/base.py:162: FutureWarning: The 'SingleTableMetadata' is deprecated. Please use the new 'Metadata' class for synthesizers.\n",
            "/usr/local/lib/python3.11/dist-packages/sdv/single_table/base.py:128: UserWarning: We strongly recommend saving the metadata using 'save_to_json' for replicability in future SDV versions.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Generated synthetic data for Customer\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sdv/single_table/base.py:162: FutureWarning: The 'SingleTableMetadata' is deprecated. Please use the new 'Metadata' class for synthesizers.\n",
            "/usr/local/lib/python3.11/dist-packages/sdv/single_table/base.py:128: UserWarning: We strongly recommend saving the metadata using 'save_to_json' for replicability in future SDV versions.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Generated synthetic data for Policy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sdv/single_table/base.py:162: FutureWarning: The 'SingleTableMetadata' is deprecated. Please use the new 'Metadata' class for synthesizers.\n",
            "/usr/local/lib/python3.11/dist-packages/sdv/single_table/base.py:128: UserWarning: We strongly recommend saving the metadata using 'save_to_json' for replicability in future SDV versions.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Generated synthetic data for Coverage\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sdv/single_table/base.py:162: FutureWarning: The 'SingleTableMetadata' is deprecated. Please use the new 'Metadata' class for synthesizers.\n",
            "/usr/local/lib/python3.11/dist-packages/sdv/single_table/base.py:128: UserWarning: We strongly recommend saving the metadata using 'save_to_json' for replicability in future SDV versions.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Generated synthetic data for Premium\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "for table_name, df in synthetic_data.items():\n",
        "    filename = f\"{table_name}_synthetic.csv\"\n",
        "    df.to_csv(filename, index=False)\n",
        "    files.download(filename)\n"
      ],
      "metadata": {
        "id": "YwXJRbqLpz1N",
        "outputId": "059583c7-7f27-4d39-fcad-1dc2032809f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_4be998b0-fd7a-4e54-9050-75d03622f757\", \"Customer_synthetic.csv\", 804)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_db633ff1-a1ac-4cc1-b519-50f3e3557671\", \"Policy_synthetic.csv\", 578)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_be6f4281-18a4-409d-953d-3c969790d949\", \"Coverage_synthetic.csv\", 290)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_548094ab-9882-44bc-99b4-1e93dc67a71c\", \"Premium_synthetic.csv\", 453)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 0: Install required library\n",
        "!pip install -q sdv\n",
        "\n",
        "# STEP 1: Import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sdv.single_table import CTGANSynthesizer\n",
        "from sdv.metadata import SingleTableMetadata\n",
        "from google.colab import files\n",
        "\n",
        "# STEP 2: Upload CSVs\n",
        "uploaded = files.upload()  # Upload all 10 CSV files when prompted\n",
        "\n",
        "# STEP 3: Read all files into a dictionary\n",
        "dataframes = {filename.replace('.csv', ''): pd.read_csv(filename) for filename in uploaded}"
      ],
      "metadata": {
        "id": "IoLS1tTPQw6d",
        "outputId": "8fea7576-34dd-4f0e-b4cb-f03574a71fa4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 715
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/180.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m174.1/180.2 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m180.2/180.2 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.9/139.9 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.6/13.6 MB\u001b[0m \u001b[31m62.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.5/52.5 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.8/73.8 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.5/193.5 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m34.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.2/85.2 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m97.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m80.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m43.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m60.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-2bc11380-6209-4e39-b056-92165671ee13\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-2bc11380-6209-4e39-b056-92165671ee13\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Beneficiary.csv to Beneficiary.csv\n",
            "Saving Claim.csv to Claim.csv\n",
            "Saving Coverage.csv to Coverage.csv\n",
            "Saving CoverageType.csv to CoverageType.csv\n",
            "Saving Customer.csv to Customer.csv\n",
            "Saving PaymentMethod.csv to PaymentMethod.csv\n",
            "Saving Policy.csv to Policy.csv\n",
            "Saving PolicyStatus.csv to PolicyStatus.csv\n",
            "Saving PolicyType.csv to PolicyType.csv\n",
            "Saving Premium.csv to Premium.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for name, df in dataframes.items():\n",
        "    print(f\"\\n{name} columns: {df.columns.tolist()}\")\n"
      ],
      "metadata": {
        "id": "6cbONTcBS6ol",
        "outputId": "7776d3f7-7aae-4160-9cec-0b5e9c8ea3c5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Beneficiary columns: ['beneficiary_id', 'policy_id', 'first_name', 'last_name', 'date_of_birth', 'relationship']\n",
            "\n",
            "Claim columns: ['claim_id', 'policy_id', 'date_filed', 'claim_amount', 'description']\n",
            "\n",
            "Coverage columns: ['coverage_id', 'policy_id', 'coverage_amount', 'coverage_type_id']\n",
            "\n",
            "CoverageType columns: ['coverage_id', 'coverage_name']\n",
            "\n",
            "Customer columns: ['customer_id', 'first_name', 'last_name', 'date_of_birth', 'address', 'phone_number']\n",
            "\n",
            "PaymentMethod columns: ['method_id', 'method_name']\n",
            "\n",
            "Policy columns: ['policy_id', 'policy_number', 'start_date', 'end_date', 'status_id', 'type_id', 'customer_id']\n",
            "\n",
            "PolicyStatus columns: ['status_id', 'status_name']\n",
            "\n",
            "PolicyType columns: ['type_id', 'type_name']\n",
            "\n",
            "Premium columns: ['premium_id', 'policy_id', 'amount', 'payment_method_id', 'due_date']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# STEP 4: Define synthetic sample sizes\n",
        "samples = {\n",
        "    'Customer': 100,\n",
        "    'Policy': 200,\n",
        "    'Coverage': 200,\n",
        "    'Premium': 150,\n",
        "    'Claim': 400,\n",
        "    'Beneficiary': 300\n",
        "}\n",
        "\n",
        "# STEP 5: Reusable CTGAN function\n",
        "def generate_ctgan(data, table_name, num_rows):\n",
        "    metadata = SingleTableMetadata()\n",
        "    metadata.detect_from_dataframe(data)\n",
        "    model = CTGANSynthesizer(metadata)\n",
        "    model.fit(data)\n",
        "    synthetic = model.sample(num_rows=num_rows)\n",
        "    print(f\"✅ Generated synthetic data for {table_name}\")\n",
        "    return synthetic\n",
        "\n",
        "# STEP 6: Generate synthetic data\n",
        "synthetic_data = {}\n",
        "\n",
        "# Customer (independent)\n",
        "synthetic_data['Customer'] = generate_ctgan(dataframes['Customer'], 'Customer', samples['Customer'])\n",
        "\n",
        "# Policy\n",
        "policy_input = dataframes['Policy'].copy()\n",
        "policy_input['customer_id'] = np.random.choice(synthetic_data['Customer']['customer_id'], size=len(policy_input))\n",
        "policy_input['status_id'] = np.random.choice(dataframes['PolicyStatus']['status_id'], size=len(policy_input))\n",
        "policy_input['type_id'] = np.random.choice(dataframes['PolicyType']['type_id'], size=len(policy_input))\n",
        "synthetic_data['Policy'] = generate_ctgan(policy_input, 'Policy', samples['Policy'])\n",
        "\n",
        "# Coverage\n",
        "coverage_input = dataframes['Coverage'].copy()\n",
        "coverage_input['policy_id'] = np.random.choice(synthetic_data['Policy']['policy_id'], size=len(coverage_input))\n",
        "coverage_input['coverage_type_id'] = np.random.choice(dataframes['CoverageType']['coverage_id'], size=len(coverage_input))\n",
        "synthetic_data['Coverage'] = generate_ctgan(coverage_input, 'Coverage', samples['Coverage'])\n",
        "\n",
        "# Premium\n",
        "premium_input = dataframes['Premium'].copy()\n",
        "premium_input['policy_id'] = np.random.choice(synthetic_data['Policy']['policy_id'], size=len(premium_input))\n",
        "premium_input['payment_method_id'] = np.random.choice(dataframes['PaymentMethod']['method_id'], size=len(premium_input))\n",
        "synthetic_data['Premium'] = generate_ctgan(premium_input, 'Premium', samples['Premium'])\n",
        "\n",
        "# Claim\n",
        "claim_input = dataframes['Claim'].copy()\n",
        "claim_input['policy_id'] = np.random.choice(synthetic_data['Policy']['policy_id'], size=len(claim_input))\n",
        "synthetic_data['Claim'] = generate_ctgan(claim_input, 'Claim', samples['Claim'])\n",
        "\n",
        "# Beneficiary\n",
        "beneficiary_input = dataframes['Beneficiary'].copy()\n",
        "beneficiary_input['policy_id'] = np.random.choice(synthetic_data['Policy']['policy_id'], size=len(beneficiary_input))\n",
        "synthetic_data['Beneficiary'] = generate_ctgan(beneficiary_input, 'Beneficiary', samples['Beneficiary'])\n",
        "\n",
        "# STEP 7: Export synthetic tables\n",
        "for table_name, df in synthetic_data.items():\n",
        "    filename = f\"{table_name}_synthetic.csv\"\n",
        "    df.to_csv(filename, index=False)\n",
        "    files.download(filename)\n"
      ],
      "metadata": {
        "id": "oGBa5kGPPq6h",
        "outputId": "49d76e53-2e0a-4ed1-ebe8-c639a234498a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 576
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sdv/single_table/base.py:162: FutureWarning: The 'SingleTableMetadata' is deprecated. Please use the new 'Metadata' class for synthesizers.\n",
            "  warnings.warn(DEPRECATION_MSG, FutureWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sdv/single_table/base.py:128: UserWarning: We strongly recommend saving the metadata using 'save_to_json' for replicability in future SDV versions.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Generated synthetic data for Customer\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sdv/single_table/base.py:162: FutureWarning: The 'SingleTableMetadata' is deprecated. Please use the new 'Metadata' class for synthesizers.\n",
            "  warnings.warn(DEPRECATION_MSG, FutureWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sdv/single_table/base.py:128: UserWarning: We strongly recommend saving the metadata using 'save_to_json' for replicability in future SDV versions.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Generated synthetic data for Policy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sdv/single_table/base.py:162: FutureWarning: The 'SingleTableMetadata' is deprecated. Please use the new 'Metadata' class for synthesizers.\n",
            "  warnings.warn(DEPRECATION_MSG, FutureWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sdv/single_table/base.py:128: UserWarning: We strongly recommend saving the metadata using 'save_to_json' for replicability in future SDV versions.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Generated synthetic data for Coverage\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sdv/single_table/base.py:162: FutureWarning: The 'SingleTableMetadata' is deprecated. Please use the new 'Metadata' class for synthesizers.\n",
            "  warnings.warn(DEPRECATION_MSG, FutureWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sdv/single_table/base.py:128: UserWarning: We strongly recommend saving the metadata using 'save_to_json' for replicability in future SDV versions.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Generated synthetic data for Premium\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sdv/single_table/base.py:162: FutureWarning: The 'SingleTableMetadata' is deprecated. Please use the new 'Metadata' class for synthesizers.\n",
            "  warnings.warn(DEPRECATION_MSG, FutureWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sdv/single_table/base.py:128: UserWarning: We strongly recommend saving the metadata using 'save_to_json' for replicability in future SDV versions.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Generated synthetic data for Claim\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sdv/single_table/base.py:162: FutureWarning: The 'SingleTableMetadata' is deprecated. Please use the new 'Metadata' class for synthesizers.\n",
            "  warnings.warn(DEPRECATION_MSG, FutureWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sdv/single_table/base.py:128: UserWarning: We strongly recommend saving the metadata using 'save_to_json' for replicability in future SDV versions.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Generated synthetic data for Beneficiary\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_467938ce-f919-4f5f-aa33-3c34a01de479\", \"Customer_synthetic.csv\", 7433)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_c7c74983-108a-4003-966c-17c74f253e41\", \"Policy_synthetic.csv\", 9979)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_252a0832-8d5e-4320-abb0-df774fc8c341\", \"Coverage_synthetic.csv\", 5467)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_cc9acad1-a5a0-4ccf-a959-a8d1adfbb049\", \"Premium_synthetic.csv\", 5457)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_53b4a4bc-644c-44ab-b782-0b6d64869271\", \"Claim_synthetic.csv\", 21071)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_6be2291d-097c-451d-986b-61e27295dea6\", \"Beneficiary_synthetic.csv\", 14560)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def clean_and_format_phone(phone):\n",
        "    # Remove non-digit characters\n",
        "    digits = re.sub(r'\\D', '', str(phone))\n",
        "    # Take last 10 digits if longer\n",
        "    digits = digits[-10:] if len(digits) >= 10 else digits\n",
        "    # Format as (XXX) XXX-XXXX if 10 digits\n",
        "    if len(digits) == 10:\n",
        "        return f\"({digits[:3]}) {digits[3:6]}-{digits[6:]}\"\n",
        "    else:\n",
        "        return None  # or keep as is if not valid\n",
        "\n",
        "# Apply this to the original data before training\n",
        "dataframes['Customer']['phone_number'] = dataframes['Customer']['phone_number'].apply(clean_and_format_phone)\n",
        "\n",
        "# Then again apply after generating synthetic data\n",
        "synthetic_data['Customer']['phone_number'] = synthetic_data['Customer']['phone_number'].apply(clean_and_format_phone)\n"
      ],
      "metadata": {
        "id": "CLxitSAiob0g"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}